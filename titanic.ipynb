{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction\n",
    "\n",
    "This is a short lesson on data cleaning and classification prediction, using Kaggle's \n",
    "introductory competition, [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Imports\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, \\\n",
    "    RandomForestClassifier, ExtraTreesClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Importing The Data\n",
    "We're going to be using Pandas to work with our data, so we'll simply import our two \n",
    "csv files directly into Pandas DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To simplify our data processing, we can combine these two data frames into a single\n",
    "data frame. Since the test data frame is missing the 'Survived' column, we'll fill \n",
    "this in with `np.nan`, so we can remember which rows are test data and which are \n",
    "training data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df['Survived'] = np.nan\n",
    "df = train_df.append(test_df, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With that out of the way, let's start looking at the actual contents of our data and \n",
    "put it into a form that'll best suited for training our classifier.\n",
    "\n",
    "# Clean-up Time \n",
    "\n",
    "Now that we've loaded our data, we need to clean it up. Let's take a look at what we're \n",
    "dealing with first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived       float64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>1126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mr. John Bradley</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>1242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenfield, Mrs. Leo David (Blanche Strouse)</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17759</td>\n",
       "      <td>63.3583</td>\n",
       "      <td>D10 D12</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Snyder, Mrs. John Pillsbury (Nelle Stevenson)</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21228</td>\n",
       "      <td>82.2667</td>\n",
       "      <td>B45</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>West, Mrs. Edwy Arthur (Ada Mary Worth)</td>\n",
       "      <td>female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C.A. 34651</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Mabel Helen</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass  \\\n",
       "1125         1126       NaN       1   \n",
       "1241         1242       NaN       1   \n",
       "903           904       NaN       1   \n",
       "472           473       1.0       2   \n",
       "88             89       1.0       1   \n",
       "\n",
       "                                               Name     Sex   Age  SibSp  \\\n",
       "1125                      Cumings, Mr. John Bradley    male  39.0      1   \n",
       "1241   Greenfield, Mrs. Leo David (Blanche Strouse)  female  45.0      0   \n",
       "903   Snyder, Mrs. John Pillsbury (Nelle Stevenson)  female  23.0      1   \n",
       "472         West, Mrs. Edwy Arthur (Ada Mary Worth)  female  33.0      1   \n",
       "88                       Fortune, Miss. Mabel Helen  female  23.0      3   \n",
       "\n",
       "      Parch      Ticket      Fare        Cabin Embarked  \n",
       "1125      0    PC 17599   71.2833          C85        C  \n",
       "1241      1    PC 17759   63.3583      D10 D12        C  \n",
       "903       0       21228   82.2667          B45        S  \n",
       "472       2  C.A. 34651   27.7500          NaN        S  \n",
       "88        2       19950  263.0000  C23 C25 C27        S  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If we want to look for linear or binary relationships between \n",
    "our data and the survived value of each passenger, we need to convert this human-readable \n",
    "data into something that's more easy for a machine to understand: numbers!\n",
    "\n",
    "Let's go through this column-by-column, explaining the process for each new case as \n",
    "we come across it.\n",
    "\n",
    "# Sex\n",
    "The 'Sex' column is a great place to start because of its simplicity. There are only \n",
    "two cases to worry about, 'male' and 'female', and there isn't any missing data. So all \n",
    "we need to do is map these strings to a binary case for a classifier algorithm to understand.\n",
    "\n",
    "Let's use the mapping `{0: 'female', 1: 'male'}`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\n",
    "    'female': 0,\n",
    "    'male': 1\n",
    "}\n",
    "df['Sex'] = df['Sex'].apply(lambda x: mapping[x])\n",
    "df['Sex'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With just one step, we have our first binary column! Simple enough. Now onto the next one...\n",
    "\n",
    "# Age\n",
    "The 'Age' column is already in a nice numeric form, but let's take a look into how well \n",
    "it actually corresponds to whether a passenger survived in its current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(df['Age']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Looks like we have some NA values! Considering that age is a nice continuous value, let's just assign\n",
    "the median age to each missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "med_age = np.median(df['Age'][~pd.isna(df['Age'])])\n",
    "df['Age'] = df['Age'].fillna(med_age)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we have only real values, let's look at the correspondence between age and survival:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.06491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.06491</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived      Age\n",
       "Survived   1.00000 -0.06491\n",
       "Age       -0.06491  1.00000"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Survived', 'Age']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Quick refresher on correspondence: this value ranges between -1 and +1. \n",
    "\n",
    "A correspondence of 1 means two sets are strongly linearly \n",
    "correlated. Ideally, with a correspondence of 1, you could apply a simple formula of the form \n",
    "`y = mx + b` to map from one set to the other, with `m` being positive.\n",
    "\n",
    "A correspondence of -1 means the two sets are strongly linearly correlated as well, just ini the negative \n",
    "direction. You can still apply the mapping `y = mx + b`, but now you'd have a negative `m`.\n",
    "\n",
    "A correspondence of 0 means that the two sets you're looking at have no similarity. There exists no mapping \n",
    "from one set to the other.\n",
    "\n",
    "Back to our data! Seeing that the correspondence between age and survival is nearly zero, we need to \n",
    "see if there's anything we can do to actually compare the two columns! One popular method \n",
    "of identifying nonlinear correspondence is by binning, or making bins of ages, so we have a bin filled with \n",
    "our 0-10 year old passengers, our 11-20 year old passengers, and so on and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Age_bin\n",
       "0            1       0.0        2\n",
       "1            2       1.0        3\n",
       "2            3       1.0        2\n",
       "3            4       1.0        3\n",
       "4            5       0.0        3\n",
       "5            6       0.0        2\n",
       "6            7       0.0        5\n",
       "7            8       0.0        0\n",
       "8            9       1.0        2\n",
       "9           10       1.0        1"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_space = 10\n",
    "bin_walls = range(0, 100, bin_space)\n",
    "bin_intervals = [pd.Interval(low, low + bin_space) for low in bin_walls]\n",
    "bins = pd.IntervalIndex(bin_intervals)\n",
    "\n",
    "age_bin_mapping = {}\n",
    "for i, b in enumerate(bins):\n",
    "    age_bin_mapping[b] = i\n",
    "\n",
    "age_bins = pd.cut(df['Age'], bins=bins)\n",
    "df['Age_bin'] = age_bins.apply(lambda x: age_bin_mapping[x]).astype(int)\n",
    "\n",
    "df[['PassengerId', 'Survived', 'Age_bin']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we have all of our passengers assigned to bins! Let's see what the correspondence is for this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.051406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_bin</th>\n",
       "      <td>-0.051406</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived   Age_bin\n",
       "Survived  1.000000 -0.051406\n",
       "Age_bin  -0.051406  1.000000"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Survived', 'Age_bin']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As expected, the age bins linearly correspond with survival just as little as the raw age did.\n",
    "There might be a strong correspondence hiding here still, so let's look at the survival rate for each bin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin 0 survival rate: 0.59\n",
      "Bin 1 survival rate: 0.38\n",
      "Bin 2 survival rate: 0.33\n",
      "Bin 3 survival rate: 0.45\n",
      "Bin 4 survival rate: 0.38\n",
      "Bin 5 survival rate: 0.4\n",
      "Bin 6 survival rate: 0.24\n",
      "Bin 7 survival rate: 0.2\n"
     ]
    }
   ],
   "source": [
    "for bin_ind in age_bin_mapping.values():\n",
    "    df_bin = df[df['Age_bin'] == bin_ind]\n",
    "    if len(df_bin) == 0:\n",
    "        continue\n",
    "    print(\"Bin {} survival rate: {:.2g}\".format(\n",
    "        bin_ind, \n",
    "        len(df_bin[df_bin['Survived'] == 1]) / len(df_bin[~pd.isna(df_bin['Survived'])])\n",
    "    ))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Looking at this breakdown, there's definitely some sort of trend. Bin 0 had a much higher \n",
    "rate of survival than the others, while bins 6 and 7 had much lower rates of survival. In \n",
    "order to extract this in a more machine-readable way, we're going to expand this categorical \n",
    " column into a set of columns, one for each bin, with the value `1` if the row belongs to \n",
    " the bin and `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_bin</th>\n",
       "      <th>Age_bin_0</th>\n",
       "      <th>Age_bin_1</th>\n",
       "      <th>Age_bin_2</th>\n",
       "      <th>Age_bin_3</th>\n",
       "      <th>Age_bin_4</th>\n",
       "      <th>Age_bin_5</th>\n",
       "      <th>Age_bin_6</th>\n",
       "      <th>Age_bin_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "\n",
       "             Ticket     Fare  ... Embarked Age_bin  Age_bin_0  Age_bin_1  \\\n",
       "0         A/5 21171   7.2500  ...        S       2          0          0   \n",
       "1          PC 17599  71.2833  ...        C       3          0          0   \n",
       "2  STON/O2. 3101282   7.9250  ...        S       2          0          0   \n",
       "\n",
       "   Age_bin_2  Age_bin_3  Age_bin_4  Age_bin_5  Age_bin_6  Age_bin_7  \n",
       "0          1          0          0          0          0          0  \n",
       "1          0          1          0          0          0          0  \n",
       "2          1          0          0          0          0          0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_bins = pd.get_dummies(df['Age_bin']).add_prefix('Age_bin_')\n",
    "df = df.merge(age_bins, how='left', left_index=True, right_index=True, validate='1:1')\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we have a DataFrame with 8 extra columns, one for each age bin that we had created earlier.\n",
    "Since we've coded the age column into this new form, we can drop the old columns so we \n",
    "don't try to train on different representations of the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Age', 'Age_bin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pclass (Ticket class)\n",
    "Now that we've finished cleaning up the age data, let's move on to `Pclass`. First, we should look at its\n",
    "correspondence to see if it's already good or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass\n",
       "Survived  1.000000 -0.338481\n",
       "Pclass   -0.338481  1.000000"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Survived', 'Pclass']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A correspondence of -0.3 is actually fairly strong, compared to our previous examinations\n",
    "of the age bins. We can break this value down further to see if there are any individual \n",
    "ticket classes that show strong individual correspondences with the survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passenger class 1: 0.63\n",
      "Passenger class 2: 0.47\n",
      "Passenger class 3: 0.24\n"
     ]
    }
   ],
   "source": [
    "p_classes = sorted(df['Pclass'].unique())\n",
    "for p_class in p_classes:\n",
    "    df_class = df[df['Pclass'] == p_class]\n",
    "    survival = len(df_class[df_class['Survived'] == 1]) / len(df_class[~pd.isna(df_class['Survived'])])\n",
    "    print(\"Passenger class {}: {:.2g}\".format(p_class, survival))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With these survival rates, it looks like there is a pretty nice linear relationship in the \n",
    "data already, so we'll leave the Pclass column as-is.\n",
    "\n",
    "And just to be safe, we should check to make sure that there aren't any missing data\n",
    "from this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[pd.isna(df['Pclass'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "No missing values, good! Now we can move on to the next column to analyze.\n",
    "\n",
    "# SibSP (Siblings and spouses)\n",
    "\n",
    "Now we'll look at the column 'SibSp', the number of siblings and spouses each passenger had. As always, let's first take a look at the linear correspondence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>SibSp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.035322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived     SibSp\n",
       "Survived  1.000000 -0.035322\n",
       "SibSp    -0.035322  1.000000"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Survived', 'SibSp']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's essentially no correspondece here, so we need to dissect these values a bit to see if there's anything more to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rates:\n",
      "0 siblings/spouses: 0.24 \t(population: 608)\n",
      "1 siblings/spouses: 0.35 \t(population: 209)\n",
      "2 siblings/spouses: 0.31 \t(population: 28)\n",
      "3 siblings/spouses: 0.2 \t(population: 16)\n",
      "4 siblings/spouses: 0.14 \t(population: 18)\n",
      "5 siblings/spouses: 0 \t(population: 5)\n",
      "8 siblings/spouses: 0 \t(population: 7)\n"
     ]
    }
   ],
   "source": [
    "sib_nums = sorted(df['SibSp'].unique())\n",
    "\n",
    "print(\"Survival rates:\")\n",
    "for s in sib_nums:\n",
    "    df_s = df[df['SibSp'] == s]\n",
    "    survival = len(df_s[df_s['Survived'] == 1]) / len(df_s)\n",
    "    print(\"{} siblings/spouses: {:.2g} \\t(population: {})\".format(s, survival, len(df_s[~pd.isna(df_s['Survived'])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there's a line that can be drawn around a 'SibSp' value of 4-5. Families with many siblings or spouses didn't seem to have any survivability, so that'll make for a strong feature in our classifier. Let's make a new binary column for 'LargeSibSp' to track this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival for large SibSp: 0.0\n",
      "Survival for small SibSp: 0.3890784982935154\n"
     ]
    }
   ],
   "source": [
    "largeSibSpCutOff = 4\n",
    "df['LargeSibSp'] = df['SibSp'] > largeSibSpCutOff\n",
    "\n",
    "df_l = df[df['LargeSibSp'] == True]\n",
    "df_s = df[df['LargeSibSp'] == False]\n",
    "print(\"Survival for large SibSp: {}\".format(len(df_l[df_l['Survived'] == 1]) / len(df_l[~pd.isna(df_l['Survived'])])))\n",
    "print(\"Survival for small SibSp: {}\".format(len(df_s[df_s['Survived'] == 1]) / len(df_s[~pd.isna(df_s['Survived'])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, before moving on to the next feature, let's check for, and clean up, any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[pd.isna(df['SibSp'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Parch (Parents and children)\n",
    "\n",
    "The number of parents and children seems like a very similar mesaurement to the number of siblings and spouses. We should keep that in mind and come back to that later. For now though, we'll look at this feature on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.081629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived     Parch\n",
       "Survived  1.000000  0.081629\n",
       "Parch     0.081629  1.000000"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Survived', 'Parch']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No significant correspondence can be observed here, so let's run the same steps we did with 'SibSp':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rates:\n",
      "0 parents/children: 0.23 \t(population: 678)\n",
      "1 parents/children: 0.38 \t(population: 118)\n",
      "2 parents/children: 0.35 \t(population: 80)\n",
      "3 parents/children: 0.38 \t(population: 5)\n",
      "4 parents/children: 0 \t(population: 4)\n",
      "5 parents/children: 0.17 \t(population: 5)\n",
      "6 parents/children: 0 \t(population: 1)\n",
      "9 parents/children: 0 \t(population: 0)\n"
     ]
    }
   ],
   "source": [
    "parch_nums = sorted(df['Parch'].unique())\n",
    "\n",
    "print(\"Survival rates:\")\n",
    "for p in parch_nums:\n",
    "    df_p = df[df['Parch'] == p]\n",
    "    survival = len(df_p[df_p['Survived'] == 1]) / len(df_p)\n",
    "    print(\"{} parents/children: {:.2g} \\t(population: {})\".format(p, survival, len(df_p[~pd.isna(df_p['Survived'])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like 'SibSp', 'Parch shows a strong line between small numbers of parents/children and large. This is a bit trickier though; since there is a non-zero survival rate at 5, we can't draw our line of survival as easily as we did for 'SibSp'. Let's try breaking this into three new columns: 'SmallParch', 'MedParch', and 'LargeParch'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SmallParch'] = df['Parch'] <= 3\n",
    "df['MedParch'] = df['Parch'].between(4, 5)  # Boundaries are included\n",
    "df['LargeParch'] = df['Parch'] >= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival for small Parch: 0.39\n",
      "Survival for medium Parch: 0.11\n",
      "Survival for large Parch: 0\n"
     ]
    }
   ],
   "source": [
    "df_s = df[df['SmallParch'] == True]\n",
    "df_m = df[df['MedParch'] == True]\n",
    "df_l = df[df['LargeParch'] == True]\n",
    "\n",
    "print(\"Survival for small Parch: {:.2g}\".format(len(df_s[df_s['Survived'] == 1]) / len(df_s[~pd.isna(df_s['Survived'])])))\n",
    "print(\"Survival for medium Parch: {:.2g}\".format(len(df_m[df_m['Survived'] == 1]) / len(df_m[~pd.isna(df_m['Survived'])])))\n",
    "print(\"Survival for large Parch: {:.2g}\".format(len(df_l[df_l['Survived'] == 1]) / len(df_l[~pd.isna(df_l['Survived'])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, as usual, we should check for any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[pd.isna(df['Parch'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Now, remember that note we wanted to remember earlier about how 'Parch' and 'SibSp' sound very similar? Let's explore that now.\n",
    "\n",
    "# SibSp + Parch\n",
    "\n",
    "The columns 'SibSp' and 'Parch' showed very similar trends, so adding the two together might give even better data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rates:\n",
      "0 SibSp + Parch: 0.3 \t(population: 790)\n",
      "1 SibSp + Parch: 0.55 \t(population: 235)\n",
      "2 SibSp + Parch: 0.58 \t(population: 159)\n",
      "3 SibSp + Parch: 0.72 \t(population: 43)\n",
      "4 SibSp + Parch: 0.2 \t(population: 22)\n",
      "5 SibSp + Parch: 0.14 \t(population: 25)\n",
      "6 SibSp + Parch: 0.33 \t(population: 16)\n",
      "7 SibSp + Parch: 0 \t(population: 8)\n",
      "10 SibSp + Parch: 0 \t(population: 11)\n"
     ]
    }
   ],
   "source": [
    "df['Relatives'] = df['SibSp'] + df['Parch']\n",
    "\n",
    "nums = sorted(df['Relatives'].unique())\n",
    "\n",
    "print(\"Survival rates:\")\n",
    "for p in nums:\n",
    "    df_p = df[df['Relatives'] == p]\n",
    "    survival = len(df_p[df_p['Survived'] == 1]) / len(df_p[~pd.isna(df_p['Survived'])])\n",
    "    print(\"{} SibSp + Parch: {:.2g} \\t(population: {})\".format(p, survival, len(df_p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like, just as predicted, this data is essentially identical to what we found in each of the two individual columns above. Looking more closely, we can identify an almost-clean bell curve, centered a 'Relatives' size of around 2 or 3. The only data that throws this off is the increase in survivability from 'Relatives' values of 5 to 6. For now, let's ignore that as an anomaly and see if we can capture this Gaussian-like relationship around some ideal family size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>DistFromIdealRel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.24708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistFromIdealRel</th>\n",
       "      <td>-0.24708</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Survived  DistFromIdealRel\n",
       "Survived           1.00000          -0.24708\n",
       "DistFromIdealRel  -0.24708           1.00000"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal_relatives = 2\n",
    "\n",
    "df['DistFromIdealRel'] = np.abs(df['Relatives'] - ideal_relatives)\n",
    "\n",
    "df[['Survived', 'DistFromIdealRel']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An absolute correspondence of 0.25 is much better than what we started with for 'SibSp' or 'Parch' before (around 0.07), so this seems like it'll be a decent feature. Now we can go back in and drop the original columns from the table so they don't add noise to our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['SibSp', 'Parch', 'Relatives'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fare\n",
    "\n",
    "So far so good! Next, time to examine the relationship between the fare, or ticket price, and survival rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived      Fare\n",
       "Survived  1.000000  0.257307\n",
       "Fare      0.257307  1.000000"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Survived', 'Fare']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have one of the best correspondences we've seen! Let's keep this column as-is and move on for now.\n",
    "\n",
    "# Cabin\n",
    "\n",
    "Now it's time to explore whether a passenger's cabin location had anything to do with survivability. Before checking correspondences, I'd like to get any missing values out of the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA values: 1014\n"
     ]
    }
   ],
   "source": [
    "print(\"NA values: {}\".format(len(df[pd.isna(df['Cabin'])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a fairly significant amount of missing cabin information, so I'd like to hold off on filling in this data until we know what the existing relationship looks like.\n",
    "\n",
    "Let's first see if the fact that we're missing cabin information can tell us anything about survival rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29985443959243085\n",
      "0.6666666666666666\n",
      "0.3838383838383838\n"
     ]
    }
   ],
   "source": [
    "no_cabin = df[pd.isna(df['Cabin'])]\n",
    "yes_cabin = df[~pd.isna(df['Cabin'])]\n",
    "print(len(no_cabin[no_cabin['Survived'] == 1]) / len(no_cabin[~pd.isna(no_cabin['Survived'])]))\n",
    "print(len(yes_cabin[yes_cabin['Survived'] == 1]) / len(yes_cabin[~pd.isna(yes_cabin['Survived'])]))\n",
    "print(len(df[df['Survived'] == 1]) / len(df[~pd.isna(df['Survived'])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, it looks like having a cabin on record does affect the survival rate of the passengers (at least in our data set)! In that case, we're going to keep these \"no-cabin\" labels as their own unique property, while we break down the values for passengers who do have cabins.\n",
    "\n",
    "For cabin values, we'll start by binning them based on the cabin class (the letter preceding the cabin number). There are a few cabins that have the letter F before their actual cabin class, so let's separate the F-marked passengers for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'F E', 'F G', 'G', 'T']\n",
      "Survival rates:\n",
      "CabinClass A:\t0.47 \t(population: 22)\n",
      "CabinClass B:\t0.74 \t(population: 65)\n",
      "CabinClass C:\t0.59 \t(population: 94)\n",
      "CabinClass D:\t0.76 \t(population: 46)\n",
      "CabinClass E:\t0.75 \t(population: 41)\n",
      "CabinClass F:\t0.78 \t(population: 14)\n",
      "CabinClass F E:\t1 \t(population: 3)\n",
      "CabinClass F G:\t0 \t(population: 4)\n",
      "CabinClass G:\t0.5 \t(population: 5)\n",
      "CabinClass T:\t0 \t(population: 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "def get_cabin_class(cabin):\n",
    "    if pd.isna(cabin):\n",
    "        return np.nan\n",
    "    \n",
    "    title_search = re.search('([A-Za-z ]+)', cabin)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "df['CabinClass'] = df[~pd.isna(df['Cabin'])]['Cabin'].apply(get_cabin_class)\n",
    "\n",
    "cabin_classes = sorted(df[~pd.isna(df['CabinClass'])]['CabinClass'].unique())\n",
    "print(cabin_classes)\n",
    "\n",
    "print(\"Survival rates:\")\n",
    "for c in cabin_classes:\n",
    "    df_c = df[df['CabinClass'] == c]\n",
    "    survival = len(df_c[df_c['Survived'] == 1]) / len(df_c[~pd.isna(df_c['Survived'])])\n",
    "    print(\"CabinClass {}:\\t{:.2g} \\t(population: {})\".format(c, survival, len(df_c)))\n",
    "    \n",
    "df = df.drop(columns=['CabinClass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, it looks like this doesn't really give us any more information than we already had, aside from a small percentage of outliers in 'F G' and 'T' cabin classes. Maybe we'll circle back around to this to see if there are any slight improvements that can be made from the slight discrepancies between each cabin class..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh well, it was worth a shot! Let's just stick with our original finding then, the difference in survival rate between those with a recorded cabin number, and those without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>HasCabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCabin</th>\n",
       "      <td>0.316912</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived  HasCabin\n",
       "Survived  1.000000  0.316912\n",
       "HasCabin  0.316912  1.000000"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HasCabin'] = ~pd.isna(df['Cabin'])\n",
    "df = df.drop(columns=['Cabin'])\n",
    "df[['Survived', 'HasCabin']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name\n",
    "\n",
    "This one will be tricky. Maybe there are correspondences between the survival rates of passengers with certain titles? Let's find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr' 'Mrs' 'Miss' 'Master' 'Don' 'Rev' 'Dr' 'Mme' 'Ms' 'Major' 'Lady'\n",
      " 'Sir' 'Mlle' 'Col' 'Capt' 'Countess' 'Jonkheer' 'Dona']\n"
     ]
    }
   ],
   "source": [
    "def get_title(name):\n",
    "    if pd.isna(name):\n",
    "        return np.nan\n",
    "\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "df['Title'] = df['Name'].apply(get_title)\n",
    "titles = df['Title'].unique()\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few categories we could specify to split this into groups. \"Is a doctor\", or \"is military\", or \"is married\" (for women at least).\n",
    "\n",
    "Before any of those specifics, let's first just check the survival rate of each of these individually. Along with some extra clean-up combining titles that mean the same thing (and mapping unknown marital status titles to the same thing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rates:\n",
      "Mr:\t0.16 \t(population: 517)\n",
      "Mrs:\t0.79 \t(population: 125)\n",
      "Ms:\t0.7 \t(population: 185)\n",
      "Master:\t0.56 \t(population: 43)\n",
      "Rev:\t0 \t(population: 6)\n",
      "Dr:\t0.43 \t(population: 7)\n",
      "Mme:\t1 \t(population: 3)\n",
      "Major:\t0.5 \t(population: 2)\n",
      "Col:\t0.5 \t(population: 2)\n",
      "Capt:\t0 \t(population: 1)\n"
     ]
    }
   ],
   "source": [
    "title_map = {\n",
    "    'Miss': 'Ms',\n",
    "    'Mlle': 'Ms',\n",
    "    'Sir':  'Master',\n",
    "    'Don':  'Master',\n",
    "    'Jonkheer': 'Master',\n",
    "    'Countess': 'Mme',\n",
    "    'Lady':     'Mme',\n",
    "    'Dona':     'Mme'\n",
    "}\n",
    "\n",
    "def map_title(title):\n",
    "    if pd.isna(title):\n",
    "        return np.nan\n",
    "    \n",
    "    if title in title_map.keys():\n",
    "        return title_map[title]\n",
    "    else:\n",
    "        return title\n",
    "    \n",
    "df['Title'] = df['Title'].apply(map_title)\n",
    "titles = df['Title'].unique()\n",
    "\n",
    "print(\"Survival rates:\")\n",
    "for t in titles:\n",
    "    df_t = df[df['Title'] == t]\n",
    "    survival = len(df_t[df_t['Survived'] == 1]) / max(1, len(df_t[~pd.isna(df_t['Survived'])]))\n",
    "    print(\"{}:\\t{:.2g} \\t(population: {})\".format(t, survival, len(df_t[~pd.isna(df_t['Survived'])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the old saying \"the captain must go down with the ship\" holds in this case! Also, \"Masters\" fared much better than men with \"Mr\". The women with \"Mme\" also fared quite well, even though there are only 3 in this case. Reverends, on the other hand, all went down with the ship.\n",
    "\n",
    "For code simplicity, let's just go ahead and expand this column into binary columns like we did previously with age groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_bin_0</th>\n",
       "      <th>Age_bin_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Major</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "\n",
       "                                                Name  Sex            Ticket  \\\n",
       "0                            Braund, Mr. Owen Harris    1         A/5 21171   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0          PC 17599   \n",
       "2                             Heikkinen, Miss. Laina    0  STON/O2. 3101282   \n",
       "\n",
       "      Fare Embarked  Age_bin_0  Age_bin_1  ...  Title_Capt  Title_Col  \\\n",
       "0   7.2500        S          0          0  ...           0          0   \n",
       "1  71.2833        C          0          0  ...           0          0   \n",
       "2   7.9250        S          0          0  ...           0          0   \n",
       "\n",
       "   Title_Dr  Title_Major  Title_Master  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0         0            0             0          0         1          0   \n",
       "1         0            0             0          0         0          1   \n",
       "2         0            0             0          0         0          0   \n",
       "\n",
       "   Title_Ms  Title_Rev  \n",
       "0         0          0  \n",
       "1         0          0  \n",
       "2         1          0  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_bins = pd.get_dummies(df['Title']).add_prefix('Title_')\n",
    "df = df.merge(title_bins, how='left', left_index=True, right_index=True, validate='1:1')\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Name', 'Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embarked\n",
    "\n",
    "Now, almost done with the basic data cleaning for our data set! Next, it's time to look at the 'Embarked' column. From the data sheet, this column represents a passenger's port of embarkation and is encoded with one of three letters: C (Cherbourg), Q (Queenstown), or S (Southampton). Let's first take a look at the survival rate of passengers from each port to see if there's a trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rates:\n",
      "S:\t0.34 \t(population: 644)\n",
      "C:\t0.55 \t(population: 168)\n",
      "Q:\t0.39 \t(population: 77)\n",
      "nan:\t1 \t(population: 2)\n"
     ]
    }
   ],
   "source": [
    "ports = df['Embarked'].unique()\n",
    "\n",
    "print(\"Survival rates:\")\n",
    "for p in ports:\n",
    "    if pd.isna(p):\n",
    "        df_p = df[pd.isna(df['Embarked'])]\n",
    "    else:\n",
    "        df_p = df[df['Embarked'] == p]\n",
    "    survival = len(df_p[df_p['Survived'] == 1]) / max(1, len(df_p[~pd.isna(df_p['Survived'])]))\n",
    "    print(\"{}:\\t{:.2g} \\t(population: {})\".format(p, survival, len(df_p[~pd.isna(df_p['Survived'])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does look like there might be a trend here that could be worth extracting: passengers from port C show higher survival rates than those from the other two. Let's expand the 'Embarked' column into binary columns. \n",
    "\n",
    "Also, since the sample size of passengers with no port data is so small, we should go ahead and just add them to the most common port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n"
     ]
    }
   ],
   "source": [
    "groups = df.groupby('Embarked').size()\n",
    "most_common_index = groups[groups == max(groups)].index[0]\n",
    "df['Embarked'] = df['Embarked'].fillna(most_common_index)\n",
    "\n",
    "print(most_common_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age_bin_0</th>\n",
       "      <th>Age_bin_1</th>\n",
       "      <th>Age_bin_2</th>\n",
       "      <th>Age_bin_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Major</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex            Ticket     Fare  Age_bin_0  \\\n",
       "0            1       0.0       3    1         A/5 21171   7.2500          0   \n",
       "1            2       1.0       1    0          PC 17599  71.2833          0   \n",
       "2            3       1.0       3    0  STON/O2. 3101282   7.9250          0   \n",
       "\n",
       "   Age_bin_1  Age_bin_2  Age_bin_3  ...  Title_Major  Title_Master  Title_Mme  \\\n",
       "0          0          1          0  ...            0             0          0   \n",
       "1          0          0          1  ...            0             0          0   \n",
       "2          0          1          0  ...            0             0          0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Embarked_C  Embarked_Q  \\\n",
       "0         1          0         0          0           0           0   \n",
       "1         0          1         0          0           1           0   \n",
       "2         0          0         1          0           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_bins = pd.get_dummies(df['Embarked']).add_prefix('Embarked_')\n",
    "df = df.merge(embarked_bins, how='left', left_index=True, right_index=True, validate='1:1')\n",
    "\n",
    "df = df.drop(columns='Embarked')\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ticket\n",
    "Now, for the last field, the tickets. There seems to be a lot going on in this field, so we're going to have to do some string searching gymnastics to uncover any possble correlations to survival rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929\n",
      "['A/5 21171' 'PC 17599' 'STON/O2. 3101282' '113803' '373450' '330877'\n",
      " '17463' '349909' '347742' '237736' 'PP 9549' '113783' 'A/5. 2151'\n",
      " '347082' '350406' '248706' '382652' '244373' '345763' '2649']\n"
     ]
    }
   ],
   "source": [
    "tickets = df['Ticket'].unique()\n",
    "print(len(tickets))\n",
    "print(tickets[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tickets have a number, but only some have prefixes, and that prefix seems to have a hold of variation. Let's start cleaning this up to see how many different prefixes there really are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'A. 2.',\n",
       " 'A./5.',\n",
       " 'A.5.',\n",
       " 'A/4',\n",
       " 'A/4.',\n",
       " 'A/5',\n",
       " 'A/5.',\n",
       " 'A/S',\n",
       " 'A4.',\n",
       " 'AQ/3.',\n",
       " 'AQ/4',\n",
       " 'C',\n",
       " 'C.A.',\n",
       " 'C.A./SOTON',\n",
       " 'CA',\n",
       " 'CA.',\n",
       " 'F.C.',\n",
       " 'F.C.C.',\n",
       " 'Fa',\n",
       " 'LINE',\n",
       " 'LP',\n",
       " 'P/PP',\n",
       " 'PC',\n",
       " 'PP',\n",
       " 'S.C./A.4.',\n",
       " 'S.C./PARIS',\n",
       " 'S.O./P.P.',\n",
       " 'S.O.C.',\n",
       " 'S.O.P.',\n",
       " 'S.P.',\n",
       " 'S.W./PP',\n",
       " 'SC',\n",
       " 'SC/A.3',\n",
       " 'SC/A4',\n",
       " 'SC/AH',\n",
       " 'SC/AH Basle',\n",
       " 'SC/PARIS',\n",
       " 'SC/Paris',\n",
       " 'SCO/W',\n",
       " 'SO/C',\n",
       " 'SOTON/O.Q.',\n",
       " 'SOTON/O2',\n",
       " 'SOTON/OQ',\n",
       " 'STON/O 2.',\n",
       " 'STON/O2.',\n",
       " 'STON/OQ.',\n",
       " 'SW/PP',\n",
       " 'W./C.',\n",
       " 'W.E.P.',\n",
       " 'W/C',\n",
       " 'WE/P']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ticket_prefix(ticket):\n",
    "    if pd.isna(ticket):\n",
    "        return np.nan\n",
    "\n",
    "    pref = re.sub('[0-9]+$', '', ticket).strip(' ')\n",
    "    return pref\n",
    "\n",
    "df['TicketPrefix'] = df['Ticket'].apply(ticket_prefix)\n",
    "prefixes = sorted(df['TicketPrefix'].unique())\n",
    "prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we've narrowed down the results just a bit. It looks like there are different formats for the same prefix in many cases, like `['A./5', 'A/5.', 'A/5']` or `['C.A.', 'CA']`. We should make an attempt to clean these up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'a2', 'a4', 'a5', 'aq3', 'aq4', 'as', 'c', 'ca', 'casoton', 'fa', 'fc', 'fcc', 'line', 'lp', 'pc', 'pp', 'ppp', 'sc', 'sca3', 'sca4', 'scah', 'scahbasle', 'scow', 'scparis', 'soc', 'sop', 'sopp', 'sotono2', 'sotonoq', 'sp', 'stono2', 'stonoq', 'swpp', 'wc', 'wep']\n"
     ]
    }
   ],
   "source": [
    "def simplify_prefix(prefix):\n",
    "    prefix = prefix.lower()\n",
    "    prefix = prefix.replace(' ', '')\n",
    "    prefix = prefix.replace('.', '')\n",
    "    prefix = prefix.replace('/', '')\n",
    "    \n",
    "    return prefix\n",
    "\n",
    "df['TicketPrefix'] = df['TicketPrefix'].apply(simplify_prefix)\n",
    "prefixes = sorted(df['TicketPrefix'].unique())\n",
    "print(prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering these tickets were all commissioned manually - no computers back then - there could've been discrepencies in the way a ticket master wrote the details. Possibly `sop`, `sp`, and `sopp` were the same classification, as well as the pair `soton` and `ston`. And considering the prefixes starting with 'a', it really looks like `as` was a typo for `a5`. Without making too many assumptions, let's start with just these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'a2', 'a4', 'a5', 'aq3', 'aq4', 'c', 'ca', 'ca5ton', 'fa', 'fc', 'fcc', 'line', 'lp', 'pc', 'pp', 'ppp', 'sc', 'sca3', 'sca4', 'scah', 'scahba5le', 'scow', 'scparis', 'soc', 'sp', 'spp', 'stono2', 'stonoq', 'swpp', 'wc', 'wep']\n"
     ]
    }
   ],
   "source": [
    "def simplify_prefix(prefix):\n",
    "    prefix = prefix.replace('sop', 'sp')\n",
    "    prefix = prefix.replace('sopp', 'sp')\n",
    "    prefix = prefix.replace('soton', 'ston')\n",
    "    prefix = prefix.replace('as', 'a5')\n",
    "    \n",
    "    return prefix\n",
    "\n",
    "df['TicketPrefix'] = df['TicketPrefix'].apply(simplify_prefix)\n",
    "prefixes = sorted(df['TicketPrefix'].unique())\n",
    "print(prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\t0.38 \t(population: 661)\n",
      "a2:\t0 \t(population: 0)\n",
      "a4:\t0 \t(population: 7)\n",
      "a5:\t0.091 \t(population: 22)\n",
      "aq3:\t0 \t(population: 0)\n",
      "aq4:\t0 \t(population: 0)\n",
      "c:\t0.4 \t(population: 5)\n",
      "ca:\t0.34 \t(population: 41)\n",
      "ca5ton:\t0 \t(population: 1)\n",
      "fa:\t0 \t(population: 1)\n",
      "fc:\t0 \t(population: 1)\n",
      "fcc:\t0.8 \t(population: 5)\n",
      "line:\t0.25 \t(population: 4)\n",
      "lp:\t0 \t(population: 0)\n",
      "pc:\t0.65 \t(population: 60)\n",
      "pp:\t0.67 \t(population: 3)\n",
      "ppp:\t0.5 \t(population: 2)\n",
      "sc:\t1 \t(population: 1)\n",
      "sca3:\t0 \t(population: 0)\n",
      "sca4:\t0 \t(population: 1)\n",
      "scah:\t0.5 \t(population: 2)\n",
      "scahba5le:\t1 \t(population: 1)\n",
      "scow:\t0 \t(population: 1)\n",
      "scparis:\t0.45 \t(population: 11)\n",
      "soc:\t0.17 \t(population: 6)\n",
      "sp:\t0 \t(population: 2)\n",
      "spp:\t0 \t(population: 3)\n",
      "stono2:\t0.4 \t(population: 20)\n",
      "stonoq:\t0.13 \t(population: 15)\n",
      "swpp:\t1 \t(population: 2)\n",
      "wc:\t0.1 \t(population: 10)\n",
      "wep:\t0.33 \t(population: 3)\n"
     ]
    }
   ],
   "source": [
    "for p in prefixes:\n",
    "    df_p = df[df['TicketPrefix'] == p]\n",
    "    survival = len(df_p[df_p['Survived'] == 1]) / max(1, len(df_p[~pd.isna(df_p['Survived'])]))\n",
    "    print(\"{}:\\t{:.2g} \\t(population: {})\".format(p, survival, len(df_p[~pd.isna(df_p['Survived'])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many of these ticket prefixes, there are too few passengers for us to really be able to draw any conclusion. Let's try merging some of the other prefixes that have similar survival rates and prefix structure, then expand these into new binary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age_bin_0</th>\n",
       "      <th>Age_bin_1</th>\n",
       "      <th>Age_bin_2</th>\n",
       "      <th>Age_bin_3</th>\n",
       "      <th>...</th>\n",
       "      <th>TicketPrefix</th>\n",
       "      <th>TicketPrefix_A</th>\n",
       "      <th>TicketPrefix_C</th>\n",
       "      <th>TicketPrefix_Empty</th>\n",
       "      <th>TicketPrefix_FCC</th>\n",
       "      <th>TicketPrefix_Other</th>\n",
       "      <th>TicketPrefix_P</th>\n",
       "      <th>TicketPrefix_SP</th>\n",
       "      <th>TicketPrefix_STON</th>\n",
       "      <th>TicketPrefix_W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>a5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>pc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>stono2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex            Ticket     Fare  Age_bin_0  \\\n",
       "0            1       0.0       3    1         A/5 21171   7.2500          0   \n",
       "1            2       1.0       1    0          PC 17599  71.2833          0   \n",
       "2            3       1.0       3    0  STON/O2. 3101282   7.9250          0   \n",
       "\n",
       "   Age_bin_1  Age_bin_2  Age_bin_3  ...  TicketPrefix  TicketPrefix_A  \\\n",
       "0          0          1          0  ...            a5               1   \n",
       "1          0          0          1  ...            pc               0   \n",
       "2          0          1          0  ...        stono2               0   \n",
       "\n",
       "   TicketPrefix_C  TicketPrefix_Empty  TicketPrefix_FCC  TicketPrefix_Other  \\\n",
       "0               0                   0                 0                   0   \n",
       "1               0                   0                 0                   0   \n",
       "2               0                   0                 0                   0   \n",
       "\n",
       "   TicketPrefix_P  TicketPrefix_SP  TicketPrefix_STON  TicketPrefix_W  \n",
       "0               0                0                  0               0  \n",
       "1               1                0                  0               0  \n",
       "2               0                0                  1               0  \n",
       "\n",
       "[3 rows x 43 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prefix_bin(prefix):\n",
    "    if prefix == '':\n",
    "        return 'Empty'\n",
    "    if prefix[:1] == 'a':\n",
    "        return 'A'\n",
    "    if prefix[:1] == 'c':\n",
    "        return 'C'\n",
    "    if prefix[:1] == 'p':\n",
    "        return 'P'\n",
    "    if prefix[:1] == 'w':\n",
    "        return 'W'\n",
    "    \n",
    "    if prefix[:3] == 'fcc':\n",
    "        return 'FCC'\n",
    "    if prefix[:2] == 'sp':\n",
    "        return 'SP'\n",
    "    if prefix[:2] == 'scp':\n",
    "        return 'SCP'\n",
    "    if prefix[:4] == 'ston':\n",
    "        return 'STON'\n",
    "\n",
    "    return 'Other'\n",
    "\n",
    "df['TicketPrefix_Bin'] = df['TicketPrefix'].apply(prefix_bin)\n",
    "\n",
    "prefix_bins = pd.get_dummies(df['TicketPrefix_Bin']).add_prefix('TicketPrefix_')\n",
    "df = df.merge(prefix_bins, how='left', left_index=True, right_index=True, validate='1:1')\n",
    "\n",
    "df = df.drop(columns=['TicketPrefix_Bin'])\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now , at least, that's a wrap for data cleaning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Classification\n",
    "\n",
    "Now we can actually put our data to use and try to make a survival classifier out of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Vizualize Data Relationships\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = df.corr().abs()\n",
    "\n",
    "plt.matshow(df.corr().abs())\n",
    "cb = plt.colorbar()\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Split data into X and y\n"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes('number').columns\n",
    "df_numeric = df[num_cols]\n",
    "\n",
    "train_df = df_numeric[~pd.isna(df_numeric['Survived'])]\n",
    "train_df = train_df.dropna()\n",
    "survived = train_df.pop('Survived')\n",
    "\n",
    "test_df = df_numeric[pd.isna(df_numeric['Survived'])]\n",
    "_ = test_df.pop('Survived')\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "X = train_df.to_numpy()\n",
    "y = survived.to_numpy()\n",
    "\n",
    "test_p = 0.7\n",
    "t = int(test_p * len(y))\n",
    "X_test = X[:t]\n",
    "X_train = X[t:]\n",
    "y_test = y[:t]\n",
    "y_train = y[t:]\n",
    "\n",
    "X_final = test_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Try SVM\n"
    }
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='scale', kernel='linear', random_state=0, decision_function_shape='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Try LinearSVM\n"
    }
   },
   "outputs": [],
   "source": [
    "lin_clf = svm.LinearSVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Try Adaboost with random forest\n"
    }
   },
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators=10, random_state=0), \n",
    "                             n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Try Gradient Boosting\n"
    }
   },
   "outputs": [],
   "source": [
    "gr_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Try random forest\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Try EXTRA random forest\n"
    }
   },
   "outputs": [],
   "source": [
    "erf_clf = ExtraTreesClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Put them all together with a voting booster\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vanilla SVC\n",
      "- train: 0.8283582089552238\n",
      "- test: 0.7961476725521669\n",
      "\n",
      "Linear SVC\n",
      "- train: 0.6865671641791045\n",
      "- test: 0.666131621187801\n",
      "\n",
      "AdaBoost, random forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blakemacnair/anaconda3/envs/titanic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train: 1.0\n",
      "- test: 0.7704654895666132\n",
      "\n",
      "Gradient Boosting, random forest\n",
      "- train: 0.9664179104477612\n",
      "- test: 0.7720706260032103\n",
      "\n",
      "Random Forest\n",
      "- train: 1.0\n",
      "- test: 0.7993579454253612\n",
      "\n",
      "Extra Trees\n",
      "- train: 1.0\n",
      "- test: 0.7993579454253612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blakemacnair/anaconda3/envs/titanic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====\n",
      "Voting Classifier:\n",
      "- train: 0.9776119402985075\n",
      "- test: 0.8089887640449438\n"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(estimators=[('Vanilla SVC', clf),\n",
    "                                    ('Linear SVC', lin_clf),\n",
    "                                    ('AdaBoost, random forest', ada_clf), \n",
    "                                    ('Gradient Boosting, random forest', gr_clf),\n",
    "                                    ('Random Forest', rf_clf),\n",
    "                                    ('Extra Trees', erf_clf),\n",
    "                                    ], voting='hard')\n",
    "for clft in eclf.estimators:\n",
    "    print(\"\\n\"+clft[0])\n",
    "    clf = clft[1]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"- train: {}\\n- test: {}\".format(clf.score(X_train, y_train), \n",
    "                                           clf.score(X_test, y_test)))\n",
    "eclf.fit(X_train, y_train)\n",
    "print(\"\\n====\\nVoting Classifier:\\n- train: {}\\n- test: {}\".format(eclf.score(X_train, y_train), \n",
    "                                                           eclf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Generate the output for the actual test predictions\n"
    }
   },
   "outputs": [],
   "source": [
    "y_final = eclf.predict(X_final)\n",
    "df_final = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': y_final.astype(int)\n",
    "})\n",
    "\n",
    "df_final.to_csv(\"data/pred.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
