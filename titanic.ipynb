{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Titanic Survival Prediction\n",
    "\n",
    "This is a short lesson on data cleaning and classification prediction, using Kaggle's \n",
    "introductory competition, [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% Imports\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, \\\n",
    "    RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing The Data\n",
    "We're going to be using Pandas to work with our data, so we'll simply import our two \n",
    "csv files directly into Pandas DataFrames:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "To simplify our data processing, we can combine these two data frames into a single\n",
    "data frame. Since the test data frame is missing the 'Survived' column, we'll fill \n",
    "this in with `np.nan`, so we can remember which rows are test data and which are \n",
    "training data later on."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "test_df['Survived'] = np.nan\n",
    "df = train_df.append(test_df, sort=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With that out of the way, let's start looking at the actual contents of our data and \n",
    "put it into a form that'll best suited for training our classifier.\n",
    "\n",
    "# Clean-up Time \n",
    "\n",
    "Now that we've loaded our data, we need to clean it up. Let's take a look at what we're \n",
    "dealing with first:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId      int64\nSurvived       float64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId  Survived  Pclass                         Name   Sex   Age  \\\n170         1062       NaN       3           Lithman, Mr. Simon  male   NaN   \n561          562       0.0       3            Sivic, Mr. Husein  male  40.0   \n300         1192       NaN       3    Olsson, Mr. Oscar Wilhelm  male  32.0   \n124          125       0.0       1  White, Mr. Percival Wayland  male  54.0   \n753          754       0.0       3           Jonkoff, Mr. Lalio  male  23.0   \n\n     SibSp  Parch         Ticket     Fare Cabin Embarked  \n170      0      0  S.O./P.P. 251   7.5500   NaN        S  \n561      0      0         349251   7.8958   NaN        S  \n300      0      0         347079   7.7750   NaN        S  \n124      0      1          35281  77.2875   D26        S  \n753      0      0         349204   7.8958   NaN        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>170</th>\n      <td>1062</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Lithman, Mr. Simon</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>S.O./P.P. 251</td>\n      <td>7.5500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>561</th>\n      <td>562</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Sivic, Mr. Husein</td>\n      <td>male</td>\n      <td>40.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>349251</td>\n      <td>7.8958</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>1192</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Olsson, Mr. Oscar Wilhelm</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>347079</td>\n      <td>7.7750</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>125</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>White, Mr. Percival Wayland</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>35281</td>\n      <td>77.2875</td>\n      <td>D26</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>753</th>\n      <td>754</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Jonkoff, Mr. Lalio</td>\n      <td>male</td>\n      <td>23.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>349204</td>\n      <td>7.8958</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "df.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we want to look for linear or binary relationships between \n",
    "our data and the survived value of each passenger, we need to convert this human-readable \n",
    "data into something that's more easy for a machine to understand: numbers!\n",
    "\n",
    "Let's go through this column-by-column, explaining the process for each new case as \n",
    "we come across it.\n",
    "\n",
    "# Sex\n",
    "The 'Sex' column is a great place to start because of its simplicity. There are only \n",
    "two cases to worry about, 'male' and 'female', and there isn't any missing data. So all \n",
    "we need to do is map these strings to a binary case for a classifier algorithm to understand.\n",
    "\n",
    "Let's use the mapping `{0: 'female', 1: 'male'}`:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0    1\n1    0\n2    0\nName: Sex, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "mapping = {\n",
    "    'female': 0,\n",
    "    'male': 1\n",
    "}\n",
    "df['Sex'] = df['Sex'].apply(lambda x: mapping[x])\n",
    "df['Sex'][:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With just one step, we have our first binary column! Simple enough. Now onto the next one...\n",
    "\n",
    "# Age\n",
    "The 'Age' column is already in a nice numeric form, but let's take a look into how well \n",
    "it actually corresponds to whether a passenger survived in its current state."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "263"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "pd.isna(df['Age']).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looks like we have some NA values! Considering that age is a nice continuous value, let's just assign\n",
    "the median age to each missing value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "med_age = np.median(df['Age'][~pd.isna(df['Age'])])\n",
    "df['Age'] = df['Age'].fillna(med_age)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have only real values, let's look at the correspondence between age and survival:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "          Survived      Age\nSurvived   1.00000 -0.06491\nAge       -0.06491  1.00000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Survived</th>\n      <td>1.00000</td>\n      <td>-0.06491</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>-0.06491</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "df[['Survived', 'Age']].corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quick refresher on correspondence: this value ranges between -1 and +1. \n",
    "\n",
    "A correspondence of 1 means two sets are strongly linearly \n",
    "correlated. Ideally, with a correspondence of 1, you could apply a simple formula of the form \n",
    "`y = mx + b` to map from one set to the other, with `m` being positive.\n",
    "\n",
    "A correspondence of -1 means the two sets are strongly linearly correlated as well, just ini the negative \n",
    "direction. You can still apply the mapping `y = mx + b`, but now you'd have a negative `m`.\n",
    "\n",
    "A correspondence of 0 means that the two sets you're looking at have no similarity. There exists no mapping \n",
    "from one set to the other.\n",
    "\n",
    "Back to our data! Seeing that the correspondence between age and survival is nearly zero, we need to \n",
    "see if there's anything we can do to actually compare the two columns! One popular method \n",
    "of identifying nonlinear correspondence is by binning, or making bins of ages, so we have a bin filled with \n",
    "our 0-10 year old passengers, our 11-20 year old passengers, and so on and so forth."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0    2\n1    3\n2    2\n3    3\n4    3\n5    2\n6    5\n7    0\n8    2\n9    1\nName: Age_bin, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "bin_space = 10\n",
    "bin_walls = range(0, 100, bin_space)\n",
    "bin_intervals = [pd.Interval(low, low + bin_space) for low in bin_walls]\n",
    "bins = pd.IntervalIndex(bin_intervals)\n",
    "\n",
    "age_bin_mapping = {}\n",
    "for i, b in enumerate(bins):\n",
    "    age_bin_mapping[b] = i\n",
    "\n",
    "age_bins = pd.cut(df['Age'], bins=bins)\n",
    "df['Age_bin'] = age_bins.apply(lambda x: age_bin_mapping[x]).astype(int)\n",
    "\n",
    "df['Age_bin'][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have all of our passengers assigned to bins! Let's see what the correspondence is for this..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "          Survived   Age_bin\nSurvived  1.000000 -0.051406\nAge_bin  -0.051406  1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Age_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Survived</th>\n      <td>1.000000</td>\n      <td>-0.051406</td>\n    </tr>\n    <tr>\n      <th>Age_bin</th>\n      <td>-0.051406</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "df[['Survived', 'Age_bin']].corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected, the age bins linearly correspond with survival just as little as the raw age did.\n",
    "There might be a strong correspondence hiding here still, so let's look at the survival rate for each bin:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Bin 0 survival rate: 0.44\nBin 1 survival rate: 0.27\nBin 2 survival rate: 0.22\nBin 3 survival rate: 0.33\nBin 4 survival rate: 0.25\nBin 5 survival rate: 0.27\nBin 6 survival rate: 0.15\nBin 7 survival rate: 0.17\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for bin_ind in age_bin_mapping.values():\n",
    "    df_bin = df[df['Age_bin'] == bin_ind]\n",
    "    if len(df_bin) == 0:\n",
    "        continue\n",
    "    print(\"Bin {} survival rate: {:.2g}\".format(\n",
    "        bin_ind, \n",
    "        len(df_bin[df_bin['Survived'] == 1]) / len(df_bin)\n",
    "    ))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at this breakdown, there's definitely some sort of trend. Bin 0 had a much higher \n",
    "rate of survival than the others, while bins 6 and 7 had much lower rates of survival. In \n",
    "order to extract this in a more machine-readable way, we're going to expand this categorical \n",
    " column into a set of columns, one for each bin, with the value `1` if the row belongs to \n",
    " the bin and `0` otherwise."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "age_bins = pd.get_dummies(df['Age_bin']).add_prefix('Age_bin_')\n",
    "df = df.join(age_bins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass                     Name  Sex   Age  SibSp  \\\n0            1       0.0       3  Braund, Mr. Owen Harris    1  22.0      1   \n\n   Parch     Ticket  Fare  ... Embarked Age_bin  Age_bin_0  Age_bin_1  \\\n0      0  A/5 21171  7.25  ...        S       2          0          0   \n\n   Age_bin_2  Age_bin_3  Age_bin_4  Age_bin_5  Age_bin_6  Age_bin_7  \n0          1          0          0          0          0          0  \n\n[1 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>...</th>\n      <th>Embarked</th>\n      <th>Age_bin</th>\n      <th>Age_bin_0</th>\n      <th>Age_bin_1</th>\n      <th>Age_bin_2</th>\n      <th>Age_bin_3</th>\n      <th>Age_bin_4</th>\n      <th>Age_bin_5</th>\n      <th>Age_bin_6</th>\n      <th>Age_bin_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.25</td>\n      <td>...</td>\n      <td>S</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "df[:1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have a DataFrame with 8 extra columns, one for each age bin that we had created earlier.\n",
    "Since we've coded the age column into this new form, we can drop the old columns so we \n",
    "don't try to train on different representations of the same data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Age', 'Age_bin'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pclass (Ticket class)\n",
    "Now that we've finished cleaning up the age data, let's move on to `Pclass`. First, we should look at its\n",
    "correspondence to see if it's already good or not."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "          Survived    Pclass\nSurvived  1.000000 -0.309447\nPclass   -0.309447  1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Survived</th>\n      <td>1.000000</td>\n      <td>-0.309447</td>\n    </tr>\n    <tr>\n      <th>Pclass</th>\n      <td>-0.309447</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "df[['Survived', 'Pclass']].corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A correspondence of -0.3 is actually fairly strong, compared to our previous examinations\n",
    "of the age bins. We can break this value down further to see if there are any individual \n",
    "ticket classes that show strong individual correspondences with the survival rate."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Passenger class 1: 0.36\nPassenger class 2: 0.28\nPassenger class 3: 0.16\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [PassengerId, Survived, Pclass, Name, Sex, SibSp, Parch, Ticket, Fare, Cabin, Embarked, Age_bin_0, Age_bin_1, Age_bin_2, Age_bin_3, Age_bin_4, Age_bin_5, Age_bin_6, Age_bin_7]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Age_bin_0</th>\n      <th>Age_bin_1</th>\n      <th>Age_bin_2</th>\n      <th>Age_bin_3</th>\n      <th>Age_bin_4</th>\n      <th>Age_bin_5</th>\n      <th>Age_bin_6</th>\n      <th>Age_bin_7</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 23
    }
   ],
   "source": [
    "p_classes = sorted(df['Pclass'].unique())\n",
    "for p_class in p_classes:\n",
    "    df_class = df[df['Pclass'] == p_class]\n",
    "    survival = len(df_class[df_class['Survived'] == 1]) / len(df_class)\n",
    "    print(\"Passenger class {}: {:.2g}\".format(p_class, survival))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With these survival rates, it looks like there is a pretty nice linear relationship in the \n",
    "data already, so we'll leave the Pclass column as-is.\n",
    "\n",
    "And just to be safe, we should check to make sure that there aren't any missing data\n",
    "from this column."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 27
    }
   ],
   "source": [
    "len(df[pd.isna(df['Pclass'])])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No missing values, good! Now we can move on to the next column to analyze.\n",
    "\n",
    "# SibSP (Siblings and spouses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parch (Parents and children)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-372e19719163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0mt_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-372e19719163>\u001b[0m in \u001b[0;36mclean\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_as_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Age bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'col_as_numeric' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'col_as_numeric' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "def get_title(name):\n",
    "\ttitle_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "\t# If the title exists, extract and return it.\n",
    "\tif title_search:\n",
    "\t\treturn title_search.group(1)\n",
    "\treturn \"\"\n",
    "\n",
    "def categorize_titles(df):\n",
    "    df['Title'] = df['Name'].apply(get_title)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    df['Title'] = df['Title'].fillna('Rare')\n",
    "    return df\n",
    "\n",
    "def map_col_to_ids(df, col_name, col_id_name):\n",
    "    temp_df = pd.DataFrame({col_name: df[col_name].unique(), \n",
    "                            col_id_name:range(len(df[col_name].unique()))})\n",
    "    df = df.merge(temp_df, on=col_name, how='left')\n",
    "    return df\n",
    "\n",
    "def explode_col(df, col):\n",
    "    values = df[col].unique()\n",
    "    for val in values:\n",
    "        df[col+\"_\"+str(val)] = df[col].apply(lambda x: 1 if x == val else 0)\n",
    "    return df\n",
    "\n",
    "def clean(df):    \n",
    "    # Survived\n",
    "    if 'Survived' in df.columns:\n",
    "        df['Survived'] = df['Survived'].astype(int)\n",
    "    \n",
    "    # Age\n",
    "    df['Age'] = col_as_numeric(df['Age'], float)\n",
    "    \n",
    "    # Age bins\n",
    "    bin_cuts = [0, 11, 23, 34, 45, 57, 68, 100]\n",
    "    df['Age_bin'] = pd.cut(df['Age'], bin_cuts).apply(lambda x: str(x))\n",
    "    actual_bins = df['Age_bin'].unique()\n",
    "    for age_bin in actual_bins[:-1]:\n",
    "        if age_bin == np.nan:\n",
    "            continue\n",
    "        df[age_bin] = df['Age_bin'].apply(lambda x: 1 if x == age_bin else 0)\n",
    "    _ = df.pop('Age')\n",
    "    _ = df.pop('Age_bin')\n",
    "\n",
    "    # Sex\n",
    "    df = map_col_to_ids(df, 'Sex', 'Sex_id')\n",
    "    df = explode_col(df, 'Sex_id')\n",
    "    _ = df.pop('Sex')\n",
    "    _ = df.pop('Sex_id')\n",
    "    \n",
    "    \n",
    "    # SibSp - # of siblings / spouses aboard \n",
    "    df['SibSp'] = col_as_numeric(df['SibSp'], int, 0)\n",
    "    \n",
    "    # Parch - # of parents / children aboard\n",
    "    df['Parch'] = col_as_numeric(df['Parch'], int, 0)\n",
    "    \n",
    "    # Total relatives\n",
    "    df['Relatives'] = df['SibSp'] + df['Parch']\n",
    "    \n",
    "    # Is alone\n",
    "    df['IsAlone'] = df['Relatives'].apply(lambda x: 1 if x == 0 else 0)\n",
    "    \n",
    "    df = map_col_to_ids(df, 'Relatives', 'Relatives_id')\n",
    "    df = explode_col(df, 'Relatives_id')\n",
    "    _ = df.pop('Relatives')\n",
    "    _ = df.pop('Relatives_id')\n",
    "    \n",
    "    # Names and titles\n",
    "    df = categorize_titles(df)\n",
    "    df = map_col_to_ids(df, 'Title', 'Title_id')\n",
    "    df = explode_col(df, 'Title_id')\n",
    "    _ = df.pop('Title')\n",
    "    _ = df.pop('Title_id')\n",
    "    \n",
    "    # # Fare\n",
    "    df['Fare'] = col_as_numeric(df['Fare'], float)\n",
    "    bin_cuts = [0, 15, 25, 35, 45, 60, 200, 600]\n",
    "    df['Fare_bin'] = pd.cut(df['Fare'], bin_cuts).apply(lambda x: str(x))\n",
    "    df = map_col_to_ids(df, 'Fare_bin', 'Fare_id')\n",
    "    df = explode_col(df, 'Fare_id')\n",
    "    _ = df.pop('Fare')\n",
    "    _ = df.pop('Fare_bin')\n",
    "    _ = df.pop('Fare_id')\n",
    "     \n",
    "    # Pclass\n",
    "    df['Pclass'] = col_as_numeric(df['Pclass'], int)\n",
    "    df = map_col_to_ids(df, 'Pclass', \"Pclass_id\")\n",
    "    df = explode_col(df, 'Pclass_id')\n",
    "    _ = df.pop('Pclass')\n",
    "    _ = df.pop('Pclass_id')\n",
    "    \n",
    "    # Cabin - by letter class\n",
    "    df['CabinClass'] = df['Cabin'].apply(lambda x: x if len(x) == 0 else x[0])\n",
    "    df = map_col_to_ids(df, 'CabinClass', \"CabinClass_id\")\n",
    "    df = explode_col(df, 'CabinClass_id')\n",
    "    _ = df.pop('CabinClass')\n",
    "    _ = df.pop('CabinClass_id')\n",
    "    \n",
    "    # Embarked\n",
    "    df = map_col_to_ids(df, 'Embarked', \"Embarked_id\")\n",
    "    df = explode_col(df, 'Embarked_id')\n",
    "    _ = df.pop('Embarked')\n",
    "    _ = df.pop('Embarked_id')\n",
    "        \n",
    "    return df\n",
    "\n",
    "df = clean(train_df)\n",
    "t_df = clean(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col not in t_df.columns:\n",
    "        t_df[col] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Fill in missing data from t_df with empty (0) columns\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check correspondences to find any over 0.5 with survival \n",
    "corr = df.corr().abs()\n",
    "\n",
    "plt.matshow(df.corr().abs())\n",
    "cb = plt.colorbar()\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Vizualize Data Relationships\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes('number').columns\n",
    "df_numeric = df[num_cols]\n",
    "df_numeric = df_numeric.dropna()\n",
    "survived = df_numeric.pop('Survived')\n",
    "\n",
    "X = df_numeric.to_numpy()\n",
    "y = survived.to_numpy()\n",
    "\n",
    "test_p = 0.9\n",
    "t = int(test_p * len(y))\n",
    "X_test = X[:t]\n",
    "X_train = X[t:]\n",
    "y_test = y[:t]\n",
    "y_train = y[t:]\n",
    "\n",
    "t_num_cols = t_df.select_dtypes('number').columns\n",
    "t_df_numeric = t_df[t_num_cols]\n",
    "t_df_numeric = t_df_numeric.dropna()\n",
    "t_survived = t_df_numeric.pop('Survived')\n",
    "\n",
    "X_final = t_df_numeric.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Split data into X and y\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='scale', kernel='linear', random_state=0, decision_function_shape='ovo')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Try SVM\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lin_clf = svm.LinearSVC(random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Try LinearSVM\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators=10, random_state=0), \n",
    "                             n_estimators=100, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Try Adaboost with random forest\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gr_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Try Gradient Boosting\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Try random forest\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "erf_clf = ExtraTreesClassifier(n_estimators=100, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Try EXTRA random forest\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[('Vanilla SVC', clf),\n",
    "                                    ('Linear SVC', lin_clf),\n",
    "                                    ('AdaBoost, random forest', ada_clf), \n",
    "                                    ('Gradient Boosting, random forest', gr_clf),\n",
    "                                    ('Random Forest', rf_clf),\n",
    "                                    ('Extra Trees', erf_clf),\n",
    "                                    ], voting='hard')\n",
    "for clft in eclf.estimators:\n",
    "    print(\"\\n\"+clft[0])\n",
    "    clf = clft[1]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"- train: {}\\n- test: {}\".format(clf.score(X_train, y_train), \n",
    "                                           clf.score(X_test, y_test)))\n",
    "eclf.fit(X_train, y_train)\n",
    "print(\"\\n====\\nVoting Classifier:\\n- train: {}\\n- test: {}\".format(eclf.score(X_train, y_train), \n",
    "                                                           eclf.score(X_test, y_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Put them all together with a voting booster\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_final = eclf.predict(X_final)\n",
    "df_final = pd.DataFrame({\n",
    "    'PassengerId': t_df['PassengerId'],\n",
    "    'Survived': y_final\n",
    "})\n",
    "\n",
    "df_final.to_csv(\"data/pred.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Generate the output for the actual test predictions\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}